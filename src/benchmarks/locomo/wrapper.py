"""LoCoMo agent wrapper for benchmark assessment.

This module provides the LoCoMoAgent class that adapts a MemorySystemAdapter
to the LoCoMo benchmark interface. It handles multi-session conversation ingestion,
memory search, and question answering with adversarial question handling.

The wrapper follows the benchmark pattern from ARCHITECTURE.md section 4.

Key differences from LongMemEval:
- LoCoMo has multi-session conversations (~35 sessions per conversation)
- Questions are categorized into 5 types (Identity, Temporal, Inference, Contextual, Adversarial)
- Adversarial questions have intentionally incorrect premises
- Evidence annotations link questions to specific dialogue turns
"""

from __future__ import annotations

import logging
import time
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any, Protocol

if TYPE_CHECKING:
    from src.adapters.base import MemorySystemAdapter
    from src.benchmarks.locomo.dataset import (
        LoCoMoConversation,
        LoCoMoQuestion,
        LoCoMoSession,
        LoCoMoTurn,
        QACategory,
    )

logger = logging.getLogger(__name__)


class LLMClient(Protocol):
    """Protocol for LLM client interface.

    Implementations should provide a complete() method that generates
    text responses from messages.
    """

    def complete(
        self,
        system: str,
        messages: list[dict[str, str]],
        temperature: float = 0.0,
    ) -> LLMResponse:
        """Generate a completion from the LLM.

        Args:
            system: System prompt providing context
            messages: List of message dicts with 'role' and 'content'
            temperature: Sampling temperature (0.0 for deterministic)

        Returns:
            LLMResponse with the generated content
        """
        ...


@dataclass(slots=True)
class LLMResponse:
    """Response from an LLM completion.

    Attributes:
        content: The generated text response
        model: The model that generated the response
        usage: Token usage statistics
    """

    content: str
    model: str = ""
    usage: dict[str, int] = field(default_factory=dict)


@dataclass(slots=True)
class LoCoMoAnswer:
    """Answer generated by the agent for a LoCoMo question.

    Attributes:
        question_id: The question this answers
        answer: The generated answer text
        retrieved_memories: Number of memories used for context
        is_abstention: Whether the agent abstained from answering
        category: The QA category of the original question
        latency_ms: Response generation time in milliseconds
        metadata: Additional answer metadata (timing, model, etc.)
    """

    question_id: str
    answer: str
    retrieved_memories: int
    is_abstention: bool = False
    category: QACategory | None = None
    latency_ms: float = 0.0
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass(slots=True)
class IngestionResult:
    """Result of ingesting a conversation or session.

    Attributes:
        conversation_id: The conversation ID
        sessions_ingested: Number of sessions processed
        turns_ingested: Number of turns successfully stored
        total_turns: Total turns attempted
        errors: List of error messages encountered
    """

    conversation_id: str
    sessions_ingested: int
    turns_ingested: int
    total_turns: int
    errors: list[str] = field(default_factory=list)

    @property
    def success_rate(self) -> float:
        """Get the ingestion success rate."""
        if self.total_turns == 0:
            return 1.0
        return self.turns_ingested / self.total_turns


class LoCoMoAgent:
    """Wrapper adapting MemorySystemAdapter to LoCoMo benchmark interface.

    This agent:
    1. Ingests multi-session conversations into memory (up to 35 sessions)
    2. Retrieves relevant memories for each question
    3. Generates answers using an LLM with memory context
    4. Handles adversarial questions (Category 5) with incorrect premises
    5. Tracks evidence sessions for retrieval validation

    Example:
        ```python
        adapter = GitNotesAdapter(repo_path="/path/to/repo")
        llm = OpenAIClient(model="gpt-5-nano")
        agent = LoCoMoAgent(adapter, llm)

        # Ingest conversation (all sessions)
        for conv in dataset.conversations:
            agent.ingest_conversation(conv)

        # Answer questions
        for question in dataset.all_questions():
            answer = agent.answer_question(question)
            print(f"{question.question_id}: {answer.answer}")
        ```

    Attributes:
        adapter: The memory system adapter for storage/retrieval
        llm: The LLM client for generating answers
    """

    # Default system prompt for question answering
    DEFAULT_SYSTEM_PROMPT = (
        "You are an AI assistant that answers questions based on past conversations. "
        "Use only the provided conversation context to answer. "
        "If the information is not available in the context, say 'I don't know' or "
        "'I cannot find this information in our conversations.' "
        "Be concise and accurate."
    )

    # Category-specific prompts for better handling
    CATEGORY_PROMPTS = {
        1: (  # IDENTITY
            "Answer questions about the speakers' identity, background, and personal facts. "
            "Look for biographical details, names, relationships, and personal characteristics."
        ),
        2: (  # TEMPORAL
            "Answer questions about when events occurred. "
            "Pay attention to dates, times, sequences, and temporal relationships."
        ),
        3: (  # INFERENCE
            "Make reasonable inferences based on the conversation context. "
            "Use clues from the dialogue to predict or infer information."
        ),
        4: (  # CONTEXTUAL
            "Answer detailed questions about specific events or discussions. "
            "Focus on the specifics mentioned in the conversations."
        ),
        5: (  # ADVERSARIAL
            "Be careful: this question may contain incorrect premises. "
            "If the premise doesn't match the conversation, point this out. "
            "Don't assume the question is correct - verify against the context."
        ),
    }

    def __init__(
        self,
        adapter: MemorySystemAdapter,
        llm: LLMClient,
        *,
        memory_search_limit: int = 15,
        min_relevance_score: float = 0.0,
        system_prompt: str | None = None,
        use_category_prompts: bool = True,
        include_speaker_context: bool = True,
    ) -> None:
        """Initialize the LoCoMo agent.

        Args:
            adapter: Memory system adapter for storage and retrieval
            llm: LLM client for generating answers
            memory_search_limit: Max memories to retrieve per question
            min_relevance_score: Minimum score threshold for retrieval
            system_prompt: Custom system prompt (uses default if None)
            use_category_prompts: Whether to use category-specific prompts
            include_speaker_context: Whether to include speaker names in metadata
        """
        self._adapter = adapter
        self._llm = llm
        self._memory_search_limit = memory_search_limit
        self._min_relevance_score = min_relevance_score
        self._system_prompt = system_prompt or self.DEFAULT_SYSTEM_PROMPT
        self._use_category_prompts = use_category_prompts
        self._include_speaker_context = include_speaker_context

        # Track ingested conversations and sessions
        self._ingested_conversations: set[str] = set()
        self._ingested_sessions: dict[str, set[int]] = {}  # conv_id -> session_nums
        self._total_turns_ingested: int = 0

    @property
    def adapter(self) -> MemorySystemAdapter:
        """Get the memory adapter."""
        return self._adapter

    @property
    def ingested_conversation_count(self) -> int:
        """Get the number of ingested conversations."""
        return len(self._ingested_conversations)

    @property
    def total_turns_ingested(self) -> int:
        """Get the total number of turns ingested across all conversations."""
        return self._total_turns_ingested

    def ingest_turn(
        self,
        turn: LoCoMoTurn,
        conversation_id: str,
        session_timestamp: str = "",
    ) -> bool:
        """Ingest a single dialogue turn into memory.

        Args:
            turn: The dialogue turn to ingest
            conversation_id: ID of the parent conversation
            session_timestamp: Timestamp of the session

        Returns:
            True if ingestion succeeded, False otherwise
        """
        # Format content with speaker for better retrieval
        content = f"{turn.speaker}: {turn.text}"

        # Add image context if available
        if turn.img_caption:
            content += f" [Image: {turn.img_caption}]"

        # Build rich metadata for filtering and context
        metadata: dict[str, Any] = {
            "conversation_id": conversation_id,
            "session_num": turn.session_num,
            "dia_id": turn.dia_id,
            "speaker": turn.speaker,
            "turn_num": turn.turn_num,
        }

        if session_timestamp:
            metadata["timestamp"] = session_timestamp

        if turn.img_url:
            metadata["has_image"] = True

        # Store in memory system
        result = self._adapter.add(content, metadata)
        if result.success:
            self._total_turns_ingested += 1
            return True

        logger.warning(
            f"Failed to ingest turn {turn.dia_id} from {conversation_id}: {result.error}"
        )
        return False

    def ingest_session(
        self,
        session: LoCoMoSession,
        conversation_id: str,
    ) -> int:
        """Ingest a conversation session into memory.

        Each turn in the session is stored as a separate memory entry
        with metadata including conversation ID, session number, and speaker.

        Args:
            session: The LoCoMo session to ingest
            conversation_id: ID of the parent conversation

        Returns:
            Number of turns successfully ingested
        """
        ingested_count = 0

        for turn in session.turns:
            if self.ingest_turn(turn, conversation_id, session.timestamp):
                ingested_count += 1

        # Track session ingestion
        if conversation_id not in self._ingested_sessions:
            self._ingested_sessions[conversation_id] = set()
        self._ingested_sessions[conversation_id].add(session.session_num)

        logger.debug(
            f"Ingested {ingested_count}/{len(session.turns)} turns "
            f"from session {session.session_num} of {conversation_id}"
        )

        return ingested_count

    def ingest_conversation(self, conversation: LoCoMoConversation) -> IngestionResult:
        """Ingest all sessions from a conversation into memory.

        Args:
            conversation: The LoCoMo conversation to ingest

        Returns:
            IngestionResult with ingestion statistics
        """
        total_turns = conversation.total_turns
        turns_ingested = 0
        errors: list[str] = []

        for session in conversation.sessions:
            try:
                count = self.ingest_session(session, conversation.sample_id)
                turns_ingested += count
            except Exception as e:
                error_msg = f"Error ingesting session {session.session_num}: {e}"
                errors.append(error_msg)
                logger.error(error_msg)

        self._ingested_conversations.add(conversation.sample_id)

        result = IngestionResult(
            conversation_id=conversation.sample_id,
            sessions_ingested=len(conversation.sessions),
            turns_ingested=turns_ingested,
            total_turns=total_turns,
            errors=errors,
        )

        logger.info(
            f"Ingested conversation {conversation.sample_id}: "
            f"{turns_ingested}/{total_turns} turns across "
            f"{result.sessions_ingested} sessions"
        )

        return result

    def ingest_all_conversations(
        self,
        conversations: list[LoCoMoConversation],
    ) -> dict[str, IngestionResult]:
        """Ingest multiple conversations into memory.

        Args:
            conversations: List of conversations to ingest

        Returns:
            Dictionary mapping conversation_id to IngestionResult
        """
        results: dict[str, IngestionResult] = {}
        total_turns = 0

        for conv in conversations:
            result = self.ingest_conversation(conv)
            results[conv.sample_id] = result
            total_turns += result.turns_ingested

        logger.info(f"Ingested {total_turns} turns from {len(conversations)} conversations")
        return results

    def answer_question(
        self,
        question: LoCoMoQuestion,
        *,
        use_evidence_sessions: bool = False,
    ) -> LoCoMoAnswer:
        """Answer a LoCoMo question using retrieved memories.

        Retrieves relevant memories based on the question text, constructs
        a context window, and generates an answer using the LLM.

        Args:
            question: The LoCoMo question to answer
            use_evidence_sessions: If True, filter to evidence session IDs only
                                   (useful for ablation studies)

        Returns:
            LoCoMoAnswer with the generated response and metadata
        """
        start_time = time.perf_counter()

        # Build metadata filter if using evidence sessions (oracle mode)
        metadata_filter: dict[str, Any] | None = None
        if use_evidence_sessions and question.evidence_session_nums:
            metadata_filter = {
                "conversation_id": question.conversation_id,
                "session_num": list(question.evidence_session_nums),
            }
        elif question.conversation_id:
            # Always filter to the relevant conversation
            metadata_filter = {"conversation_id": question.conversation_id}

        # Search for relevant memories
        memories = self._adapter.search(
            query=question.question,
            limit=self._memory_search_limit,
            min_score=self._min_relevance_score,
            metadata_filter=metadata_filter,
        )

        # Build context from retrieved memories
        if memories:
            context_parts = []
            for mem in memories:
                session_num = mem.metadata.get("session_num", "?")
                context_parts.append(f"[Session {session_num}] {mem.content}")
            context = "\n\n".join(context_parts)
        else:
            context = "(No relevant conversation history found)"

        # Build the system prompt, optionally with category-specific guidance
        system = self._system_prompt
        if self._use_category_prompts:
            category_prompt = self.CATEGORY_PROMPTS.get(question.category.value, "")
            if category_prompt:
                system = f"{system}\n\n{category_prompt}"

        # Handle adversarial questions specially
        if question.is_adversarial:
            adversarial_note = (
                "\n\nNote: Verify the premise of this question against the "
                "conversation history. If the premise is incorrect, state that clearly."
            )
            system = f"{system}{adversarial_note}"

        # Construct the prompt
        user_message = (
            f"Conversation History:\n{context}\n\n"
            f"Question: {question.question}\n\n"
            "Answer based only on the conversation history above. "
            "If the information is not present, say so clearly."
        )

        # Generate answer using LLM
        response = self._llm.complete(
            system=system,
            messages=[{"role": "user", "content": user_message}],
            temperature=0.0,  # Deterministic for reproducibility
        )

        latency_ms = (time.perf_counter() - start_time) * 1000

        # Detect if answer indicates abstention
        is_abstention = self._detect_abstention(response.content)

        return LoCoMoAnswer(
            question_id=question.question_id,
            answer=response.content,
            retrieved_memories=len(memories),
            is_abstention=is_abstention,
            category=question.category,
            latency_ms=latency_ms,
            metadata={
                "model": response.model,
                "usage": response.usage,
                "conversation_id": question.conversation_id,
                "evidence_dia_ids": question.evidence,
                "evidence_sessions": list(question.evidence_session_nums),
                "is_adversarial": question.is_adversarial,
                "adversarial_answer": question.adversarial_answer,
            },
        )

    def answer_all_questions(
        self,
        questions: list[LoCoMoQuestion],
        *,
        use_evidence_sessions: bool = False,
    ) -> list[LoCoMoAnswer]:
        """Answer all LoCoMo questions.

        Args:
            questions: List of questions to answer
            use_evidence_sessions: If True, filter to evidence session IDs only

        Returns:
            List of LoCoMoAnswer objects
        """
        answers = []
        for idx, question in enumerate(questions):
            answer = self.answer_question(
                question,
                use_evidence_sessions=use_evidence_sessions,
            )
            answers.append(answer)

            if (idx + 1) % 50 == 0:
                logger.info(f"Answered {idx + 1}/{len(questions)} questions")

        logger.info(f"Answered {len(answers)} questions")
        return answers

    def answer_questions_by_category(
        self,
        questions: list[LoCoMoQuestion],
        category: QACategory,
        *,
        use_evidence_sessions: bool = False,
    ) -> list[LoCoMoAnswer]:
        """Answer questions filtered by category.

        Args:
            questions: List of all questions
            category: The QA category to filter by
            use_evidence_sessions: If True, filter to evidence session IDs only

        Returns:
            List of LoCoMoAnswer objects for the specified category
        """
        filtered = [q for q in questions if q.category == category]
        logger.info(f"Answering {len(filtered)} questions in category {category.name}")
        return self.answer_all_questions(
            filtered,
            use_evidence_sessions=use_evidence_sessions,
        )

    def _detect_abstention(self, answer: str) -> bool:
        """Detect if an answer indicates abstention (no information available).

        Checks for common patterns indicating the model couldn't find
        the requested information.

        Args:
            answer: The generated answer text

        Returns:
            True if the answer indicates abstention
        """
        answer_lower = answer.lower()

        abstention_phrases = [
            "i don't know",
            "i do not know",
            "cannot find",
            "can't find",
            "not mentioned",
            "not discussed",
            "no information",
            "not available",
            "wasn't mentioned",
            "was not mentioned",
            "wasn't discussed",
            "was not discussed",
            "not in the conversation",
            "not present in",
            "unable to find",
            "cannot determine",
            "can't determine",
            "unable to determine",
            "not specified",
            "not clear from",
            "no relevant",
            "never discussed",
            "never mentioned",
            "no record",
            "doesn't appear",
            "does not appear",
            # Adversarial-specific phrases
            "premise is incorrect",
            "incorrect premise",
            "that's not what",
            "that is not what",
            "doesn't match",
            "does not match",
            "contrary to",
        ]

        return any(phrase in answer_lower for phrase in abstention_phrases)

    def clear_memory(self) -> bool:
        """Clear all ingested memories (for test isolation).

        Returns:
            True if successful, False otherwise
        """
        result = self._adapter.clear()
        if result.success:
            self._ingested_conversations.clear()
            self._ingested_sessions.clear()
            self._total_turns_ingested = 0
            logger.debug("Cleared all memories")
        return result.success

    def get_stats(self) -> dict[str, Any]:
        """Get agent statistics.

        Returns:
            Dictionary with agent and memory statistics
        """
        adapter_stats = self._adapter.get_stats()

        # Calculate sessions per conversation
        sessions_per_conv = {
            conv_id: len(sessions) for conv_id, sessions in self._ingested_sessions.items()
        }

        return {
            "ingested_conversations": len(self._ingested_conversations),
            "total_sessions": sum(sessions_per_conv.values()),
            "total_turns": self._total_turns_ingested,
            "sessions_per_conversation": sessions_per_conv,
            "memory_search_limit": self._memory_search_limit,
            "min_relevance_score": self._min_relevance_score,
            "use_category_prompts": self._use_category_prompts,
            **adapter_stats,
        }
